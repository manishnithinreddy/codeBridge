package com.codebridge.server.service.logging;

import com.codebridge.server.dto.logging.LogEventMessage;
import com.codebridge.server.model.ServerActivityLog;
import com.codebridge.server.repository.ServerActivityLogRepository;
import com.fasterxml.jackson.databind.ObjectMapper; // Only if manual deserialization were needed
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.dao.DataAccessException;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional; // For batch save

import java.time.Instant;
import java.time.LocalDateTime;
import java.time.ZoneId;
import java.util.ArrayList;
import java.util.List;


@Service
public class LogEventConsumerService {

    private static final Logger log = LoggerFactory.getLogger(LogEventConsumerService.class);

    private final ServerActivityLogRepository serverActivityLogRepository;
    // ObjectMapper might not be needed if Jackson2JsonMessageConverter is configured globally for RabbitTemplate

    private static final int BATCH_SIZE = 100;
    private static final long BATCH_TIMEOUT_MS = 5000; // 5 seconds, matches @Scheduled fixedDelay

    // Using a final list and creating a new one when flushing to avoid CME with scheduled task
    private List<ServerActivityLog> logBatch = new ArrayList<>();
    private long lastFlushTime = System.currentTimeMillis(); // For size-based flush condition if needed

    public LogEventConsumerService(ServerActivityLogRepository serverActivityLogRepository) {
        this.serverActivityLogRepository = serverActivityLogRepository;
    }

    @RabbitListener(queues = "${codebridge.rabbitmq.activity-log.queue-name}")
    public void receiveLogEvent(LogEventMessage logEventMessage) {
        if (logEventMessage == null) {
            log.warn("Received null LogEventMessage. Discarding.");
            return;
        }

        log.debug("Received log event: Action='{}', UserID='{}', ServerID='{}', Status='{}'",
                  logEventMessage.action(), logEventMessage.platformUserId(),
                  logEventMessage.serverId(), logEventMessage.status());

        try {
            ServerActivityLog logEntity = new ServerActivityLog();
            // ID is auto-generated by @PrePersist in ServerActivityLog entity
            logEntity.setPlatformUserId(logEventMessage.platformUserId());
            logEntity.setAction(logEventMessage.action());
            logEntity.setServerId(logEventMessage.serverId());
            logEntity.setDetails(logEventMessage.details());
            logEntity.setStatus(logEventMessage.status());
            logEntity.setErrorMessage(logEventMessage.errorMessage());

            // Convert epoch millis to LocalDateTime
            if (logEventMessage.timestamp() > 0) {
                logEntity.setTimestamp(LocalDateTime.ofInstant(
                    Instant.ofEpochMilli(logEventMessage.timestamp()), ZoneId.systemDefault()
                ));
            } else {
                logEntity.setTimestamp(LocalDateTime.now()); // Fallback if timestamp is invalid
            }

            synchronized (this.logBatch) {
                this.logBatch.add(logEntity);
                if (this.logBatch.size() >= BATCH_SIZE) {
                    log.info("Log batch size trigger reached ({} items). Flushing.", this.logBatch.size());
                    flushLogBatch();
                }
            }
        } catch (Exception e) {
            log.error("Error processing received LogEventMessage: {}. Message: {}", logEventMessage, e.getMessage(), e);
            // Decide on error strategy: e.g., send to DLQ (requires DLQ setup) or discard.
            // For now, logging and discarding.
        }
    }

    @Scheduled(fixedDelay = BATCH_TIMEOUT_MS, initialDelay = BATCH_TIMEOUT_MS) // Run periodically
    public void scheduledFlush() {
        log.debug("Scheduled log batch flush triggered by timer.");
        flushLogBatch();
    }

    // Synchronized to prevent concurrent flushes from size trigger and schedule trigger
    // if they happen very close, though ArrayList operations are not inherently thread-safe for add + clear.
    // A better approach for high concurrency might involve a ConcurrentLinkedQueue and atomic operations,
    // or ensuring scheduledFlush and receiveLogEvent don't directly share state mutation without locks.
    // For now, simple synchronized on the list for add/flush operations.
    @Transactional // Make the DB operation atomic for the batch
    public synchronized void flushLogBatch() {
        List<ServerActivityLog> batchToSave;
        synchronized (this.logBatch) {
            if (this.logBatch.isEmpty()) {
                log.debug("Log batch is empty. Nothing to flush.");
                return;
            }
            // Create a copy of the current batch for saving, then clear the shared batch list
            // This minimizes lock time on the shared list.
            batchToSave = new ArrayList<>(this.logBatch);
            this.logBatch.clear();
            this.lastFlushTime = System.currentTimeMillis(); // Reset timer for size-based check if it were used
        }

        if (!batchToSave.isEmpty()) {
            log.info("Flushing activity log batch of size: {}", batchToSave.size());
            try {
                serverActivityLogRepository.saveAll(batchToSave);
                log.info("Successfully flushed {} log events to database.", batchToSave.size());
            } catch (DataAccessException e) {
                log.error("Error saving log batch to database. Batch size: {}. Error: {}",
                          batchToSave.size(), e.getMessage(), e);
                // Strategy for failed batch:
                // 1. Re-queue (might need DLQ and retry mechanism)
                // 2. Log to a file/alerting system
                // 3. Discard (current simple approach)
                // For now, items in batchToSave are lost if saveAll fails.
                // Consider adding them back to logBatch for next attempt, but be wary of poison messages/batches.
            }
        }
    }
}
